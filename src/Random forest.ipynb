{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import math\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n",
    "# import os\r\n",
    "\r\n",
    "\r\n",
    "# print(os.listdir())\r\n",
    "dataset = pd.read_csv(\"../datasets/BitcoinHeistData.csv\")\r\n",
    "dataset\r\n",
    "\r\n",
    "licitAddresses = dataset.loc[dataset['label'] == 'white']\r\n",
    "IllicitAddresses = dataset.loc[dataset['label'] != 'white']\r\n",
    "IllicitAddresses = IllicitAddresses.loc[IllicitAddresses['weight'] < 100]\r\n",
    "licit_subset = licitAddresses.sample(100000)\r\n",
    "Full_Dataset = pd.concat([IllicitAddresses,licit_subset])\r\n",
    "DATA = Full_Dataset.reset_index()\r\n",
    "\r\n",
    "Illicit = []*141412\r\n",
    "for i in range(141412):\r\n",
    "    if DATA['label'][i] == 'white' :\r\n",
    "        Illicit.append(0)\r\n",
    "    else :\r\n",
    "        Illicit.append(1)\r\n",
    "DATA['Illicit'] = Illicit\r\n",
    "\r\n",
    "DATA = DATA.sample(frac=1)\r\n",
    "DATA = DATA.reset_index()\r\n",
    "DATA = DATA.dropna()\r\n",
    "features = DATA.drop(['level_0','index','address','year','day','label'], axis=1)\r\n",
    "features\r\n",
    "\r\n",
    "\r\n",
    "labels = np.array(features['Illicit'])\r\n",
    "# Remove the labels from the features\r\n",
    "# axis 1 refers to the columns\r\n",
    "features= features.drop('Illicit', axis = 1)\r\n",
    "# Saving feature names for later use\r\n",
    "feature_list = list(features.columns)\r\n",
    "# Convert to numpy array\r\n",
    "features = np.array(features)\r\n",
    "# Split the data into training and testing sets\r\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\r\n",
    "\r\n",
    "print('Training Features Shape:', train_features.shape)\r\n",
    "print('Training Labels Shape:', train_labels.shape)\r\n",
    "print('Testing Features Shape:', test_features.shape)\r\n",
    "print('Testing Labels Shape:', test_labels.shape)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Instantiate model with 1000 decision trees\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Features Shape: (106059, 6)\n",
      "Training Labels Shape: (106059,)\n",
      "Testing Features Shape: (35353, 6)\n",
      "Testing Labels Shape: (35353,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\r\n",
    "\r\n",
    "# Number of trees in random forest\r\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\r\n",
    "# Number of features to consider at every split\r\n",
    "max_features = ['auto', 'sqrt']\r\n",
    "# Maximum number of levels in tree\r\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\r\n",
    "max_depth.append(None)\r\n",
    "# Minimum number of samples required to split a node\r\n",
    "min_samples_split = [2, 5, 10]\r\n",
    "# Minimum number of samples required at each leaf node\r\n",
    "min_samples_leaf = [1, 2, 4]\r\n",
    "# Method of selecting samples for training each tree\r\n",
    "bootstrap = [True, False]\r\n",
    "\r\n",
    "random_grid = {'n_estimators': n_estimators,\r\n",
    "               'max_features': max_features,\r\n",
    "               'max_depth': max_depth,\r\n",
    "               'min_samples_split': min_samples_split,\r\n",
    "               'min_samples_leaf': min_samples_leaf,\r\n",
    "               'bootstrap': bootstrap}\r\n",
    "\r\n",
    "\r\n",
    "rf = RandomForestClassifier()\r\n",
    "\r\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\r\n",
    "# Train the model on training data\r\n",
    "rf_random.fit(train_features, train_labels);\r\n",
    "\r\n",
    "rf_random.best_params_\r\n",
    "# predictions = rf.predict(test_features)\r\n",
    "\r\n",
    "# # some metrics to evaluate the model\r\n",
    "# print(confusion_matrix(test_labels,predictions))\r\n",
    "# print(classification_report(test_labels,predictions))\r\n",
    "# print(accuracy_score(test_labels, predictions))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n_estimators': 1577,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': True}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn import metrics\r\n",
    "\r\n",
    "best_rf = rf_random.best_estimator_\r\n",
    "pred = best_rf.predict(test_features)\r\n",
    "score = metrics.f1_score(test_labels, pred)\r\n",
    "print(\"F1 score :\", score)\r\n",
    "pscore = metrics.accuracy_score(test_labels, pred)\r\n",
    "print(\"accuracy : \", pscore)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score : 0.6043782441886707\n",
      "accuracy :  0.8016575679574577\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\r\n",
    "from numpy import mean\r\n",
    "\r\n",
    "# generate dataset\r\n",
    "\r\n",
    "# define model\r\n",
    "model = BalancedRandomForestClassifier(n_estimators=1000,max_depth=20)\r\n",
    "# define evaluation procedure\r\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
    "# evaluate model\r\n",
    "scores = cross_val_score(model, features, labels, scoring='roc_auc', cv=cv, n_jobs=-1)\r\n",
    "# summarize performance\r\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean ROC AUC: 0.793\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "feature_imp = pd.Series(rf.feature_importances_,index=['length','weight','count','looped','neighbors','income']).sort_values(ascending=False)\r\n",
    "feature_imp\r\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\r\n",
    "# Add labels to your graph\r\n",
    "plt.xlabel('Feature Importance Score')\r\n",
    "plt.ylabel('Features')\r\n",
    "plt.title(\"Visualizing Important Features\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig(\"../imgs/Random forest features importance.jpg\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.2 64-bit ('MACHINE LEARNING': conda)"
  },
  "interpreter": {
   "hash": "bafd9a389957e655fc4a14100b8046fbffdd0d44d41b67e95b7e280b879e2e60"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}